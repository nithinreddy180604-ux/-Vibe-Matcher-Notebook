{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Matcher: Mini Recommendation Notebook\n",
    "\n",
    "This notebook prototypes a lightweight vibe-based recommendation system for fashion discovery: input a vibe query → embed product descriptions → return top-3 matches via cosine similarity. It includes data prep, embeddings (OpenAI with a graceful fallback), vector search simulation, evaluation across multiple queries, latency profiling, and reflection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why AI at Nexora (Intro)\n",
    "AI at Nexora enables personalization at scale—matching evolving user vibes to dynamic product catalogs in real time. By combining high-quality text embeddings with fast similarity search, we reduce friction in discovery, increase conversion through relevance, and unlock creative merchandising strategies like vibe-driven collections and adaptive storefronts. This prototype demonstrates a pragmatic path from concept to measurable impact, including evaluation and latency profiling—laying the groundwork for production search with vector databases, caching, and continuous learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Install dependencies when running on Colab or a fresh environment.\n",
    "- Set `OPENAI_API_KEY` to use OpenAI embeddings; otherwise, notebook falls back to TF-IDF.\n",
    "\n",
    "You can set the key like: `import os; os.environ['OPENAI_API_KEY'] = 'sk-...'` or in Colab `%env OPENAI_API_KEY=...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab or a clean local env, uncomment to install:\n",
    "# !pip install -q openai pandas numpy scikit-learn matplotlib\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Helper: timing utility for latency\n",
    "def time_call(fn, *args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = fn(*args, **kwargs)\n",
    "    return result, (time.perf_counter() - start)\n",
    "\n",
    "# Threshold for a 'good' recommendation (adjustable)\n",
    "GOOD_SIM_THRESHOLD = 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "Create a small catalog of fashion products with descriptions and vibe tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\n",
    "        'name': 'Boho Dress',\n",
    "        'desc': 'Flowy silhouette in earthy tones for carefree festival vibes.',\n",
    "        'vibes': ['boho', 'earthy', 'festival']\n",
    "    },\n",
    "    {\n",
    "        'name': 'City Bomber Jacket',\n",
    "        'desc': 'Sleek urban silhouette, lightweight layering, high-energy streetwear edge.',\n",
    "        'vibes': ['urban', 'energetic', 'streetwear']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Cozy Knit Sweater',\n",
    "        'desc': 'Soft, oversized knit in neutral hues for lounge-day comfort.',\n",
    "        'vibes': ['cozy', 'minimal']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Sustainable Denim',\n",
    "        'desc': 'Recycled cotton denim with clean lines—everyday eco-friendly essential.',\n",
    "        'vibes': ['minimal', 'sustainable', 'casual']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Athleisure Set',\n",
    "        'desc': 'Breathable leggings and crop top—gym-to-brunch versatile performance.',\n",
    "        'vibes': ['sporty', 'energetic', 'casual']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Vintage Leather Boots',\n",
    "        'desc': 'Worn-in patina with rugged edge—timeless downtown statement.',\n",
    "        'vibes': ['vintage', 'rugged', 'urban']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Silk Midi Skirt',\n",
    "        'desc': 'Elegant drape with refined sheen—date-night ready sophistication.',\n",
    "        'vibes': ['chic', 'elegant', 'minimal']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Tech Parka',\n",
    "        'desc': 'Weatherproof shell with hidden pockets—commuter-ready technical function.',\n",
    "        'vibes': ['urban', 'tech', 'functional']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Floral Wrap Top',\n",
    "        'desc': 'Bright prints with playful movement—summer-friendly boho charm.',\n",
    "        'vibes': ['boho', 'playful', 'chic']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lounge Joggers',\n",
    "        'desc': 'Tapered fit with ultra-soft feel—couch-to-café comfort.',\n",
    "        'vibes': ['cozy', 'casual', 'minimal']\n",
    "    },\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(products)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Use OpenAI embeddings (`text-embedding-ada-002`), with fallback to `text-embedding-3-small` if needed, and TF-IDF if no API key or network issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_openai(texts: List[str]) -> Tuple[Optional[np.ndarray], Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Attempts to embed using OpenAI. Returns (vectors, model_used, error_message).\n",
    "    Tries 'text-embedding-ada-002' first, then 'text-embedding-3-small' if the first fails.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        return None, None, 'Missing OPENAI_API_KEY; falling back to TF-IDF.'\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        model = 'text-embedding-ada-002'\n",
    "        resp = client.embeddings.create(model=model, input=texts)\n",
    "        vecs = np.array([d.embedding for d in resp.data])\n",
    "        return vecs, model, None\n",
    "    except Exception as e1:\n",
    "        try:\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI()\n",
    "            model = 'text-embedding-3-small'\n",
    "            resp = client.embeddings.create(model=model, input=texts)\n",
    "            vecs = np.array([d.embedding for d in resp.data])\n",
    "            return vecs, model, None\n",
    "        except Exception as e2:\n",
    "            return None, None, f'OpenAI embedding failed: {e1} | {e2}'\n",
    "\n",
    "def embed_tfidf(texts: List[str]) -> np.ndarray:\n",
    "    vec = TfidfVectorizer()\n",
    "    return vec.fit_transform(texts).toarray()\n",
    "\n",
    "def get_embeddings(texts: List[str]) -> Tuple[np.ndarray, str]:\n",
    "    vecs, model, err = embed_openai(texts)\n",
    "    if vecs is not None:\n",
    "        print(f'Using OpenAI model: {model}')\n",
    "        return vecs, model\n",
    "    else:\n",
    "        print(err)\n",
    "        print('Falling back to TF-IDF embeddings for simulation.')\n",
    "        return embed_tfidf(texts), 'tfidf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build product description embeddings\n",
    "product_texts = df['desc'].tolist()\n",
    "(product_vecs, model_used), embed_latency = time_call(get_embeddings, product_texts)\n",
    "print(f'Embeddings model: {model_used} | latency: {embed_latency:.3f}s')\n",
    "df['embedding'] = list(product_vecs)\n",
    "df[['name', 'vibes']].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search Simulation\n",
    "Compute cosine similarity between the query embedding and product embeddings. Return top-3 with scores. Handle edge cases (low similarity → fallback suggestion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_top_k(df: pd.DataFrame, query: str, k: int = 3, threshold: float = 0.3):\n",
    "    product_texts = df['desc'].tolist()\n",
    "    if 'tfidf' == globals().get('model_used'):\n",
    "        combined = product_texts + [query]\n",
    "        vecs = embed_tfidf(combined)\n",
    "        X = vecs[:-1]\n",
    "        q = vecs[-1].reshape(1, -1)\n",
    "        model = 'tfidf'\n",
    "    else:\n",
    "        q_vecs, model = get_embeddings([query])\n",
    "        q = q_vecs[0].reshape(1, -1)\n",
    "        X = np.stack(df['embedding'].values)\n",
    "    sims = cosine_similarity(q, X)[0]\n",
    "    idxs = np.argsort(sims)[::-1][:k]\n",
    "    results = []\n",
    "    for i in idxs:\n",
    "        results.append({\n",
    "            'name': df.iloc[i]['name'],\n",
    "            'desc': df.iloc[i]['desc'],\n",
    "            'vibes': df.iloc[i]['vibes'],\n",
    "            'score': float(sims[i])\n",
    "        })\n",
    "    # Edge case: if all scores below threshold, propose a simple fallback\n",
    "    if all(r['score'] < threshold for r in results):\n",
    "        # Try vibe keyword match as a rule-based fallback\n",
    "        q_lower = query.lower()\n",
    "        vibe_hits = []\n",
    "        for i, row in df.iterrows():\n",
    "            if any(v in q_lower for v in row['vibes']):\n",
    "                vibe_hits.append({\n",
    "                    'name': row['name'],\n",
    "                    'desc': row['desc'],\n",
    "                    'vibes': row['vibes'],\n",
    "                    'score': 0.0\n",
    "                })\n",
    "        if vibe_hits:\n",
    "            return vibe_hits[:k], {\n",
    "                'model': model,\n",
    "                'fallback': 'vibe_keyword_match',\n",
    "            }\n",
    "        else:\n",
    "            return results, {\n",
    "                'model': model,\n",
    "                'fallback': 'no_strong_match',\n",
    "                'message': 'No strong embedding matches; consider broadening query.'\n",
    "            }\n",
    "    return results, { 'model': model, 'fallback': None }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: sample query\n",
    "query = 'energetic urban chic'\n",
    "top3, meta = match_top_k(df, query, k=3)\n",
    "print(f'Query: {query}')\n",
    "print('Model:', meta['model'], '| Fallback:', meta['fallback'])\n",
    "for r in top3:\n",
    "    print(f\"- {r['name']} (score={r['score']:.3f}) | vibes={r['vibes']}\")\n",
    "top3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test & Eval\n",
    "Run three queries, log metrics (sim score > 0.7 as 'good'), and plot latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'energetic urban chic',\n",
    "    'cozy loungewear',\n",
    "    'minimal sustainable'\n",
    "]\n",
    "\n",
    "eval_rows = []\n",
    "latencies = []\n",
    "\n",
    "for q in queries:\n",
    "    (res, meta), t = time_call(match_top_k, df, q, 3)\n",
    "    latencies.append({'query': q, 'latency_s': t})\n",
    "    top1 = res[0] if res else {'score': 0.0, 'name': 'N/A'}\n",
    "    is_good = top1['score'] >= GOOD_SIM_THRESHOLD\n",
    "    eval_rows.append({\n",
    "        'query': q,\n",
    "        'top1_name': top1['name'],\n",
    "        'top1_score': top1['score'],\n",
    "        'good': is_good,\n",
    "        'model': meta['model'],\n",
    "        'fallback': meta['fallback']\n",
    "    })\n",
    "\n",
    "pd.DataFrame(eval_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary metrics\n",
    "df_eval = pd.DataFrame(eval_rows)\n",
    "good_rate = df_eval['good'].mean() if len(df_eval) else 0.0\n",
    "avg_top1 = df_eval['top1_score'].mean() if len(df_eval) else 0.0\n",
    "print(f'Good rate (top1 >= {GOOD_SIM_THRESHOLD}): {good_rate:.2f}')\n",
    "print(f'Average top1 score: {avg_top1:.3f}')\n",
    "df_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latency plot\n",
    "df_lat = pd.DataFrame(latencies)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(df_lat['query'], df_lat['latency_s'], color='#4C78A8')\n",
    "plt.title('Query Latency (s)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "df_lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- Integrate a vector DB (e.g., Pinecone/FAISS) for scalable, persistent search.\n",
    "- Combine fields (name + desc + vibe tags) into a single embedding for richer semantics.\n",
    "- Add query expansion and MMR diversification to avoid near-duplicate top results.\n",
    "- Cache embeddings and add a small reranker (e.g., cross-encoder) for precision.\n",
    "- Better edge handling: dynamic thresholds, vibe taxonomy mapping, and guardrails for empty/ambiguous queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab/GitHub Delivery\n",
    "- Push this notebook to GitHub and open it in Colab via `https://colab.research.google.com/github/<your_org>/<repo>/blob/main/vibe_matcher.ipynb`.\n",
    "- In Colab, set `OPENAI_API_KEY` (or rely on TF-IDF fallback) and run all cells.\n",
    "- Export executed notebook (`File → Download`) to capture outputs in commits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
